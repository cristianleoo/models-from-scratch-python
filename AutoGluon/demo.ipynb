{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AutoML with AutoGluon**\n",
    "*By Cristian Leo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240630_013540\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 23.5.0: Wed May  1 20:12:58 PDT 2024; root:xnu-10063.121.3~5/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "Memory Avail:       2.01 GB / 32.00 GB (6.3%)\n",
      "Disk Space Avail:   432.56 GB / 926.35 GB (46.7%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "/Users/cristianleo/miniconda3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1242: UserWarning: Failed to use ray for memory safe fits. Falling back to normal fit. Error: ValueError('ray==2.11.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` ')\n",
      "  stacked_overfitting = self._sub_fit_memory_save_wrapper(\n",
      "\t\tContext path: \"AutogluonModels/ag-20240630_013540/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 900s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240630_013540/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    23153\n",
      "Train Data Columns: 14\n",
      "Label Column:       income\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = >50K, class 0 = <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (>50K) vs negative (<=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2051.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 12.78 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.24 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 599.72s of the 899.79s of remaining time.\n",
      "\t0.7752\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 599.57s of the 899.64s of remaining time.\n",
      "\t0.7622\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.42s of the 899.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "/Users/cristianleo/miniconda3/envs/ag/lib/python3.10/site-packages/dask/dataframe/__init__.py:49: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "\t0.8688\t = Validation score   (accuracy)\n",
      "\t22.81s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 576.35s of the 876.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.875\t = Validation score   (accuracy)\n",
      "\t14.78s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 561.45s of the 861.52s of remaining time.\n",
      "\t0.8555\t = Validation score   (accuracy)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 559.06s of the 859.14s of remaining time.\n",
      "\t0.8565\t = Validation score   (accuracy)\n",
      "\t1.88s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 556.37s of the 856.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8744\t = Validation score   (accuracy)\n",
      "\t60.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 496.28s of the 796.35s of remaining time.\n",
      "\t0.851\t = Validation score   (accuracy)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 494.74s of the 794.82s of remaining time.\n",
      "\t0.8504\t = Validation score   (accuracy)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 493.15s of the 793.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 9: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "No improvement since epoch 8: early stopping\n",
      "No improvement since epoch 8: early stopping\n",
      "\t0.8585\t = Validation score   (accuracy)\n",
      "\t138.74s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 353.96s of the 654.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8752\t = Validation score   (accuracy)\n",
      "\t10.53s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 343.27s of the 643.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8555\t = Validation score   (accuracy)\n",
      "\t184.78s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 158.29s of the 458.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.874\t = Validation score   (accuracy)\n",
      "\t51.12s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 106.88s of the 406.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8753\t = Validation score   (accuracy)\n",
      "\t43.13s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 63.66s of the 363.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 5)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 5)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 7)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 9)\n",
      "\t0.8496\t = Validation score   (accuracy)\n",
      "\t60.0s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 3.38s of the 303.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 5. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_error: 0.24076\n",
      "\tRan out of time, early stopping on iteration 21. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_error: 0.240498\n",
      "\tRan out of time, early stopping on iteration 22. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_error: 0.240498\n",
      "\tRan out of time, early stopping on iteration 14. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_error: 0.240498\n",
      "\tRan out of time, early stopping on iteration 27. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_error: 0.240843\n",
      "\tRan out of time, early stopping on iteration 29. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_error: 0.240843\n",
      "\tRan out of time, early stopping on iteration 26. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_error: 0.240843\n",
      "\tRan out of time, early stopping on iteration 40. Best iteration is:\n",
      "\t[40]\tvalid_set's binary_error: 0.205252\n",
      "\t0.7637\t = Validation score   (accuracy)\n",
      "\t3.22s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 0.09s of the 300.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_r191_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 299.9s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L1': 1.0}\n",
      "\t0.8753\t = Validation score   (accuracy)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 299.43s of the 299.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8754\t = Validation score   (accuracy)\n",
      "\t16.8s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 282.46s of the 282.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8768\t = Validation score   (accuracy)\n",
      "\t15.51s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 266.83s of the 266.76s of remaining time.\n",
      "\t0.8765\t = Validation score   (accuracy)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 262.6s of the 262.52s of remaining time.\n",
      "\t0.8761\t = Validation score   (accuracy)\n",
      "\t3.96s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 257.95s of the 257.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8772\t = Validation score   (accuracy)\n",
      "\t24.46s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 233.4s of the 233.32s of remaining time.\n",
      "\t0.8766\t = Validation score   (accuracy)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 231.74s of the 231.66s of remaining time.\n",
      "\t0.8749\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 229.87s of the 229.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 0: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "\t0.8753\t = Validation score   (accuracy)\n",
      "\t152.98s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 76.46s of the 76.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8776\t = Validation score   (accuracy)\n",
      "\t11.23s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 65.06s of the 64.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 6)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 8)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 9)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 10)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 11)\n",
      "\t0.8737\t = Validation score   (accuracy)\n",
      "\t61.9s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 2.44s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L2': 1.0}\n",
      "\t0.8776\t = Validation score   (accuracy)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 898.25s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1842.7 rows/s (2895 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240630_013540/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                        model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       NeuralNetTorch_BAG_L2       0.864940   0.873666    accuracy        2.723598       4.189155  655.942723                 0.298999                0.294527          61.902682            2       True         27\n",
      "1           LightGBMXT_BAG_L2       0.864594   0.875437    accuracy        2.510891       3.959893  610.836657                 0.086292                0.065265          16.796616            2       True         18\n",
      "2             LightGBM_BAG_L1       0.864249   0.875005    accuracy        0.106439       0.061759   14.781336                 0.106439                0.061759          14.781336            1       True          4\n",
      "3      NeuralNetFastAI_BAG_L2       0.863903   0.875265    accuracy        2.994679       4.150294  747.016349                 0.570080                0.255666         152.976308            2       True         25\n",
      "4             CatBoost_BAG_L2       0.863558   0.877208    accuracy        2.470547       3.924336  618.498241                 0.045948                0.029708          24.458200            2       True         22\n",
      "5        LightGBMLarge_BAG_L1       0.863212   0.873969    accuracy        0.156479       0.093830   51.120786                 0.156479                0.093830          51.120786            1       True         13\n",
      "6             LightGBM_BAG_L2       0.863212   0.876776    accuracy        2.521166       3.941300  609.548860                 0.096567                0.046672          15.508819            2       True         19\n",
      "7              XGBoost_BAG_L1       0.862867   0.875221    accuracy        0.170112       0.103812   10.525304                 0.170112                0.103812          10.525304            1       True         11\n",
      "8              XGBoost_BAG_L2       0.862867   0.877597    accuracy        2.569786       3.990700  605.265467                 0.145187                0.096072          11.225427            2       True         26\n",
      "9         WeightedEnsemble_L3       0.862867   0.877597    accuracy        2.571031       3.992112  605.946907                 0.001245                0.001412           0.681440            3       True         28\n",
      "10    RandomForestEntr_BAG_L2       0.862522   0.876085    accuracy        2.560799       4.446695  598.004930                 0.136200                0.552067           3.964889            2       True         21\n",
      "11      ExtraTreesEntr_BAG_L2       0.860449   0.874876    accuracy        2.574409       4.503102  595.161922                 0.149810                0.608474           1.121882            2       True         24\n",
      "12       CatBoost_r177_BAG_L1       0.860104   0.875265    accuracy        0.033882       0.037000   43.134708                 0.033882                0.037000          43.134708            1       True         14\n",
      "13        WeightedEnsemble_L2       0.860104   0.875265    accuracy        0.035271       0.038601   43.589877                 0.001389                0.001601           0.455169            2       True         17\n",
      "14            CatBoost_BAG_L1       0.859758   0.874401    accuracy        0.047418       0.041775   60.006196                 0.047418                0.041775          60.006196            1       True          7\n",
      "15    RandomForestGini_BAG_L2       0.859758   0.876474    accuracy        2.562053       4.493922  597.549861                 0.137454                0.599294           3.509821            2       True         20\n",
      "16          LightGBMXT_BAG_L1       0.858031   0.868829    accuracy        0.188516       0.132141   22.810141                 0.188516                0.132141          22.810141            1       True          3\n",
      "17      ExtraTreesGini_BAG_L2       0.856995   0.876560    accuracy        2.646675       4.501531  594.924221                 0.222076                0.606903           0.884180            2       True         23\n",
      "18    RandomForestGini_BAG_L1       0.846978   0.855526    accuracy        0.176155       0.629463    1.586814                 0.176155                0.629463           1.586814            1       True          5\n",
      "19    RandomForestEntr_BAG_L1       0.846632   0.856520    accuracy        0.184129       0.642760    1.875026                 0.184129                0.642760           1.875026            1       True          6\n",
      "20     NeuralNetFastAI_BAG_L1       0.844905   0.858550    accuracy        0.363648       0.276603  138.741704                 0.363648                0.276603         138.741704            1       True         10\n",
      "21      NeuralNetTorch_BAG_L1       0.842487   0.855526    accuracy        0.187441       0.147107  184.780809                 0.187441                0.147107         184.780809            1       True         12\n",
      "22      ExtraTreesEntr_BAG_L1       0.841451   0.850387    accuracy        0.218765       0.648075    0.745483                 0.218765                0.648075           0.745483            1       True          9\n",
      "23      ExtraTreesGini_BAG_L1       0.836960   0.851034    accuracy        0.266838       0.648758    0.663156                 0.266838                0.648758           0.663156            1       True          8\n",
      "24  NeuralNetTorch_r79_BAG_L1       0.834197   0.849566    accuracy        0.253791       0.211778   60.004188                 0.253791                0.211778          60.004188            1       True         15\n",
      "25      KNeighborsUnif_BAG_L1       0.784801   0.775191    accuracy        0.019635       0.100699    0.022507                 0.019635                0.100699           0.022507            1       True          1\n",
      "26      KNeighborsDist_BAG_L1       0.774784   0.762191    accuracy        0.018036       0.095885    0.022380                 0.018036                0.095885           0.022380            1       True          2\n",
      "27       LightGBM_r131_BAG_L1       0.759240   0.763746    accuracy        0.033315       0.023182    3.219502                 0.033315                0.023182           3.219502            1       True         16\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t903s\t = DyStack   runtime |\t2697s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2697s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240630_013540\"\n",
      "Train Data Rows:    26048\n",
      "Train Data Columns: 14\n",
      "Label Column:       income\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = >50K, class 0 = <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (>50K) vs negative (<=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2153.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 14.37 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.2s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.39 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1797.59s of the 2697.06s of remaining time.\n",
      "\t0.7748\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1797.43s of the 2696.89s of remaining time.\n",
      "\t0.7645\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1797.25s of the 2696.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8683\t = Validation score   (accuracy)\n",
      "\t27.87s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1769.12s of the 2668.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t18.6s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1750.35s of the 2649.81s of remaining time.\n",
      "\t0.8548\t = Validation score   (accuracy)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1748.19s of the 2647.65s of remaining time.\n",
      "\t0.8551\t = Validation score   (accuracy)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1745.9s of the 2645.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8733\t = Validation score   (accuracy)\n",
      "\t76.19s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1669.63s of the 2569.09s of remaining time.\n",
      "\t0.8493\t = Validation score   (accuracy)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1667.79s of the 2567.26s of remaining time.\n",
      "\t0.8488\t = Validation score   (accuracy)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1666.07s of the 2565.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 9: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "\t0.8591\t = Validation score   (accuracy)\n",
      "\t149.53s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1516.12s of the 2415.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t14.79s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1501.16s of the 2400.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8558\t = Validation score   (accuracy)\n",
      "\t252.84s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1248.12s of the 2147.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8722\t = Validation score   (accuracy)\n",
      "\t45.88s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1201.97s of the 2101.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8744\t = Validation score   (accuracy)\n",
      "\t44.28s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1157.61s of the 2057.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8505\t = Validation score   (accuracy)\n",
      "\t290.43s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 866.88s of the 1766.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_error: 0.124079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8745\t = Validation score   (accuracy)\n",
      "\t44.95s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 821.47s of the 1720.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 22: early stopping\n",
      "No improvement since epoch 12: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 11: early stopping\n",
      "\t0.8578\t = Validation score   (accuracy)\n",
      "\t405.92s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 414.83s of the 1314.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8737\t = Validation score   (accuracy)\n",
      "\t63.5s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 351.24s of the 1250.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8643\t = Validation score   (accuracy)\n",
      "\t23.32s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 327.63s of the 1227.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 19)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 24)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 25)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 28)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 28)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 30)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 35)\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 44)\n",
      "\t0.855\t = Validation score   (accuracy)\n",
      "\t313.09s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 14.17s of the 913.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8687\t = Validation score   (accuracy)\n",
      "\t13.46s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 0.47s of the 899.93s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 45 due to low time. Expected time usage reduced from 3.0s -> 0.5s...\n",
      "\t0.8464\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 0.08s of the 899.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping CatBoost_r137_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 899.29s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
      "\t0.8748\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 898.58s of the 898.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8762\t = Validation score   (accuracy)\n",
      "\t19.65s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 878.81s of the 878.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8767\t = Validation score   (accuracy)\n",
      "\t19.45s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 859.21s of the 859.12s of remaining time.\n",
      "\t0.8736\t = Validation score   (accuracy)\n",
      "\t5.43s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 853.03s of the 852.94s of remaining time.\n",
      "\t0.8753\t = Validation score   (accuracy)\n",
      "\t6.25s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 846.06s of the 845.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8762\t = Validation score   (accuracy)\n",
      "\t22.2s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 823.76s of the 823.67s of remaining time.\n",
      "\t0.8734\t = Validation score   (accuracy)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 821.68s of the 821.59s of remaining time.\n",
      "\t0.8741\t = Validation score   (accuracy)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 819.53s of the 819.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 0: early stopping\n",
      "No improvement since epoch 6: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "\t0.8755\t = Validation score   (accuracy)\n",
      "\t139.23s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 679.84s of the 679.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8769\t = Validation score   (accuracy)\n",
      "\t11.18s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 668.47s of the 668.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8743\t = Validation score   (accuracy)\n",
      "\t158.47s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 509.62s of the 509.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8765\t = Validation score   (accuracy)\n",
      "\t38.09s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 471.24s of the 471.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8768\t = Validation score   (accuracy)\n",
      "\t16.43s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 454.71s of the 454.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -596.83s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r177_BAG_L2': 0.25, 'RandomForestEntr_BAG_L2': 0.208, 'XGBoost_BAG_L2': 0.167, 'LightGBMLarge_BAG_L2': 0.167, 'NeuralNetTorch_r22_BAG_L1': 0.083, 'XGBoost_BAG_L1': 0.042, 'NeuralNetTorch_BAG_L1': 0.042, 'LightGBMXT_BAG_L2': 0.042}\n",
      "\t0.8779\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3294.86s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1005.0 rows/s (3256 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240630_013540\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance on Test Data: {'accuracy': 0.8820819898664211, 'balanced_accuracy': 0.8144024471263216, 'mcc': 0.6645581396914595, 'roc_auc': 0.9321996393041522, 'f1': 0.7366255144032922, 'precision': 0.7985130111524164, 'recall': 0.6836409929980903}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Adult Income dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "data = pd.read_csv(url, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
    "data.dropna(inplace=True)  # Remove rows with missing values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the label\n",
    "label = 'income'\n",
    "\n",
    "# Initialize the TabularPredictor\n",
    "predictor = TabularPredictor(label=label).fit(train_data=train_data, presets='best_quality')\n",
    "\n",
    "# Evaluate the model\n",
    "performance = predictor.evaluate(test_data)\n",
    "\n",
    "# Display results\n",
    "print(\"Model Performance on Test Data:\", performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
